[2024-10-27T21:14:32.120+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: holiday_etl_pipeline.extract_to_landing manual__2024-10-27T21:14:30.499501+00:00 [queued]>
[2024-10-27T21:14:32.127+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: holiday_etl_pipeline.extract_to_landing manual__2024-10-27T21:14:30.499501+00:00 [queued]>
[2024-10-27T21:14:32.128+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 2
[2024-10-27T21:14:32.137+0000] {taskinstance.py:2191} INFO - Executing <Task(_PythonDecoratedOperator): extract_to_landing> on 2024-10-27 21:14:30.499501+00:00
[2024-10-27T21:14:32.142+0000] {standard_task_runner.py:60} INFO - Started process 89 to run task
[2024-10-27T21:14:32.145+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'holiday_etl_pipeline', 'extract_to_landing', 'manual__2024-10-27T21:14:30.499501+00:00', '--job-id', '19', '--raw', '--subdir', 'DAGS_FOLDER/holidays_orchestror.py', '--cfg-path', '/tmp/tmpnvg0cel6']
[2024-10-27T21:14:32.147+0000] {standard_task_runner.py:88} INFO - Job 19: Subtask extract_to_landing
[2024-10-27T21:14:32.185+0000] {task_command.py:423} INFO - Running <TaskInstance: holiday_etl_pipeline.extract_to_landing manual__2024-10-27T21:14:30.499501+00:00 [running]> on host f28df99dfa84
[2024-10-27T21:14:32.243+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='holiday_etl_pipeline' AIRFLOW_CTX_TASK_ID='extract_to_landing' AIRFLOW_CTX_EXECUTION_DATE='2024-10-27T21:14:30.499501+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-10-27T21:14:30.499501+00:00'
[2024-10-27T21:14:48.687+0000] {spark_session.py:55} ERROR - Erro ao criar sessão Spark: Java gateway process exited before sending its port number
[2024-10-27T21:14:48.687+0000] {spark_session.py:56} ERROR - Python Path: /usr/local/bin/python
[2024-10-27T21:14:48.688+0000] {spark_session.py:57} ERROR - Environment: environ({'AIRFLOW__CELERY__RESULT_BACKEND': 'db+postgresql://***:***@postgres/***', 'DUMB_INIT_SETSID': '0', 'HOSTNAME': 'f28df99dfa84', 'PYTHON_VERSION': '3.11.8', 'LANGUAGE': 'C.UTF-8', 'JAVA_HOME': '/usr/lib/jvm/java-17-openjdk-amd64', 'AIRFLOW_USER_HOME_DIR': '/home/***', 'ADDITIONAL_RUNTIME_APT_DEPS': '', 'PWD': '/opt/***', 'AIRFLOW__CELERY__BROKER_URL': 'redis://:@redis:6379/0', 'AIRFLOW_VERSION': '2.8.1', 'AIRFLOW__CORE__LOAD_EXAMPLES': 'false', 'AIRFLOW__API__AUTH_BACKENDS': '***.api.auth.backend.basic_auth,***.api.auth.backend.session', 'INSTALL_MSSQL_CLIENT': 'true', 'PYTHON_SETUPTOOLS_VERSION': '65.5.1', 'INSTALL_MYSQL_CLIENT_TYPE': 'mariadb', 'GUNICORN_CMD_ARGS': '--worker-tmp-dir /dev/shm', 'LD_PRELOAD': '/usr/lib/x86_64-linux-gnu/libstdc++.so.6', 'HOME': '/home/***', 'LANG': 'C.UTF-8', 'AIRFLOW_HOME': '/opt/***', 'GPG_KEY': 'A035C8C19219BA821ECEA86B64E628F8D684696D', 'AIRFLOW__DATABASE__SQL_ALCHEMY_CONN': 'postgresql+psycopg2://***:***@postgres/***', 'AIRFLOW__CORE__EXECUTOR': 'CeleryExecutor', 'COMMIT_SHA': 'c0ffa9c5d96625c68ded9562632674ed366b5eb3', 'AIRFLOW_PIP_VERSION': '23.3.2', 'AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION': 'true', 'ADDITIONAL_RUNTIME_APT_COMMAND': '', 'INSTALL_POSTGRES_CLIENT': 'true', 'SHLVL': '0', 'LC_MESSAGES': 'C.UTF-8', 'RUNTIME_APT_DEPS': '', 'PYTHON_PIP_VERSION': '24.0', 'RUNTIME_APT_COMMAND': 'echo', 'LD_LIBRARY_PATH': '/usr/local/lib', 'LC_CTYPE': 'C.UTF-8', 'AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK': 'true', 'PYTHON_GET_PIP_SHA256': 'dfe9fd5c28dc98b5ac17979a953ea550cec37ae1b47a5116007395bfacff2ab9', 'AIRFLOW_INSTALLATION_METHOD': '', 'LC_ALL': 'C.UTF-8', 'PYTHON_GET_PIP_URL': 'https://github.com/pypa/get-pip/raw/dbf0c85f76fb6e1ab42aa672ffca6f0a675d9ee4/public/get-pip.py', 'INSTALL_MYSQL_CLIENT': 'true', 'PATH': '/root/bin:/home/***/.local/bin:/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/lib/jvm/java-17-openjdk-amd64/bin', 'PYTHON_BASE_IMAGE': 'python:3.11-slim-bookworm', 'AIRFLOW_UID': '50000', 'BUILD_ID': '', 'AIRFLOW__CORE__FERNET_KEY': '', 'DEBIAN_FRONTEND': 'noninteractive', 'AIRFLOW_CONN_SPARK_DEFAULT': 'spark://spark-master:7077', '_MP_FORK_LOGLEVEL_': '20', '_MP_FORK_LOGFILE_': '', '_MP_FORK_LOGFORMAT_': '[%(asctime)s: %(levelname)s/%(processName)s] %(message)s', 'CELERY_LOG_LEVEL': '20', 'CELERY_LOG_FILE': '', 'CELERY_LOG_REDIRECT': '1', 'CELERY_LOG_REDIRECT_LEVEL': 'WARNING', '_AIRFLOW_PARSING_CONTEXT_DAG_ID': 'holiday_etl_pipeline', '_AIRFLOW_PARSING_CONTEXT_TASK_ID': 'extract_to_landing', 'AIRFLOW_CTX_DAG_OWNER': '***', 'AIRFLOW_CTX_DAG_ID': 'holiday_etl_pipeline', 'AIRFLOW_CTX_TASK_ID': 'extract_to_landing', 'AIRFLOW_CTX_EXECUTION_DATE': '2024-10-27T21:14:30.499501+00:00', 'AIRFLOW_CTX_TRY_NUMBER': '1', 'AIRFLOW_CTX_DAG_RUN_ID': 'manual__2024-10-27T21:14:30.499501+00:00', 'PYSPARK_PYTHON': '/usr/local/bin/python', 'PYSPARK_DRIVER_PYTHON': '/usr/local/bin/python'})
[2024-10-27T21:14:48.689+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/opt/airflow/dags/conf/spark_session.py", line 45, in get_session
    cls._instance = builder.getOrCreate()
                    ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/pyspark/sql/session.py", line 477, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/pyspark/context.py", line 512, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.11/site-packages/pyspark/context.py", line 198, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.11/site-packages/pyspark/context.py", line 432, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/decorators/base.py", line 241, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/holidays_orchestror.py", line 39, in extract_holidays
    return HolidayLandingOrchestrator.extract_holidays()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/scripts/landing/holliday_landing.py", line 201, in extract_holidays
    extractor = HolidayLanding()
                ^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/scripts/landing/holliday_landing.py", line 68, in __init__
    self.spark = SparkSessionManager.get_session()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/conf/spark_session.py", line 58, in get_session
    raise Exception(error_msg)
Exception: Erro ao criar sessão Spark: Java gateway process exited before sending its port number
[2024-10-27T21:14:48.700+0000] {taskinstance.py:1138} INFO - Marking task as UP_FOR_RETRY. dag_id=holiday_etl_pipeline, task_id=extract_to_landing, execution_date=20241027T211430, start_date=20241027T211432, end_date=20241027T211448
[2024-10-27T21:14:48.710+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 19 for task extract_to_landing (Erro ao criar sessão Spark: Java gateway process exited before sending its port number; 89)
[2024-10-27T21:14:48.721+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-10-27T21:14:48.736+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
